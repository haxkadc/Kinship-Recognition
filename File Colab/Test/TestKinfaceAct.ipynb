{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestKinfaceAct.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWOQhaYL_aQ1",
        "outputId": "393e1370-1909-4a52-80d4-6a94e6bcd0c2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgh_RYau_kHA"
      },
      "source": [
        "#some of blocks below are not used.\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "# import vgg_pytorch as vp\n",
        "# Data visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fastai\n",
        "from fastai.vision import *\n",
        "from fastai.vision.models import *\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision.models import *\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.autograd import Variable\n",
        "#import pretrainedmodels\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import dlib\n",
        "import cv2\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(42)#To make sure that each time you run this kernal, you will get the same beginning parameters.\n",
        "\n",
        "BATCH_SIZE=16\n",
        "NUMBER_EPOCHS=10\n",
        "IMG_SIZE=224\n",
        "\n",
        "pathDir  = 'drive/MyDrive/Dataset_Actor/Kinface-Act/'\n",
        "pathDir =   'drive/MyDrive/Dataset_Ignoti/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tpjLy1R_9Z1"
      },
      "source": [
        "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = vgg16(pretrained=True)# wide_resnet50_2(pretrained=True)##vp.VGG.from_pretrained('vgg16')#resnet50 doesn't work, might because pretrained model recognize all faces as the same.\n",
        "        #self.ccn1.classifier =  nn.Linear(100*100, )\n",
        "        # #Freeze training for all layers\n",
        "        for param in self.cnn1.features.parameters():\n",
        "          param.require_grad = False\n",
        "\n",
        "\n",
        "\n",
        "        #Newly created modules have require_grad=True by default\n",
        "        num_features = self.cnn1.classifier[3].in_features\n",
        "        features = list(self.cnn1.classifier.children())[:-3] # Remove last layer\n",
        "\n",
        "        self.cnn1.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "        # features.extend([nn.Linear(num_features, 1000)]) # Add our layer with 4 outputs\n",
        "        # features.extend([nn.ReLU(inplace=True)])\n",
        "        # features.extend([nn.Dropout()]) # Add our layer with 4 outputs\n",
        "        # self.cnn1.classifier[3].out_features = 5\n",
        "        self.new_classifier = features\n",
        "        # self.pool =  nn.MaxPool2d\n",
        "        self.fc1 = nn.Linear(num_features*2, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 500)\n",
        "        self.fc3 = nn.Linear(500, 5)\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2):#did not know how to let two resnet share the same param.\n",
        "        # self.cnn1.classifier = nn.Sequential(*self.new_classifier).cuda()\n",
        "        output1 = self.cnn1(input1)\n",
        "        output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.\n",
        "        #output1 = F.max_pool2d(output1,kernel_size=3)\n",
        "        #output1 = self.pool(2)(output1)\n",
        "        #output1 = torch.cat((output1,output1),1)\n",
        "        output2 = self.cnn1(input2)\n",
        "        output2 = output2.view(output2.size()[0], -1)\n",
        "        # output2 = self.pool(2)(output2)\n",
        "        #output2 = torch.cat((output2,output2),1)\n",
        "        substract_out = torch.subtract(output1,output2)\n",
        "        diffal2 = torch.multiply(substract_out,substract_out)\n",
        "        molt = torch.multiply(output1,output2)\n",
        "        output1al2 = torch.multiply(output1,output1)\n",
        "        output2al2 = torch.multiply(output2,output2)\n",
        "        diffdei2 = torch.abs(torch.subtract(output1al2,output2al2))\n",
        "\n",
        "        output = torch.cat((diffal2, molt),1)\n",
        "        output = F.relu(self.fc1(output))\n",
        "        output = F.relu(self.fc2(output))\n",
        "        output = self.fc3(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HkB3ZeNDSMV"
      },
      "source": [
        "# class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
        "#     def __init__(self):\n",
        "#         super(SiameseNetwork, self).__init__()\n",
        "#         self.cnn1 = vgg16(pretrained=True)# wide_resnet50_2(pretrained=True)##vp.VGG.from_pretrained('vgg16')#resnet50 doesn't work, might because pretrained model recognize all faces as the same.\n",
        "#         #self.ccn1.classifier =  nn.Linear(100*100, )\n",
        "#         # #Freeze training for all layers\n",
        "#         for param in self.cnn1.features.parameters():\n",
        "#           param.require_grad = False\n",
        "        \n",
        "#         for param in self.cnn1.classifier.parameters():\n",
        "#           param.require_grad = False\n",
        "\n",
        "\n",
        "\n",
        "#         #Newly created modules have require_grad=True by default\n",
        "#         num_features = self.cnn1.classifier[3].in_features\n",
        "#         features = list(self.cnn1.classifier.children())[:-3] # Remove last layer\n",
        "        \n",
        "#         self.cnn1.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "#         # features.extend([nn.Linear(num_features, 1000)]) # Add our layer with 4 outputs\n",
        "#         # features.extend([nn.ReLU(inplace=True)])\n",
        "#         # features.extend([nn.Dropout()]) # Add our layer with 4 outputs\n",
        "#         # self.cnn1.classifier[3].out_features = 5\n",
        "#         self.new_classifier = features\n",
        "#         # self.pool =  nn.MaxPool2d\n",
        "#         self.fc1 = nn.Linear(num_features*3, 1024)\n",
        "#         self.fc2 = nn.Linear(1024, 500)\n",
        "#         self.fc3 = nn.Linear(500, 4)\n",
        "\n",
        "\n",
        "#     def forward(self, input1, input2):#did not know how to let two resnet share the same param.\n",
        "#         # self.cnn1.classifier = nn.Sequential(*self.new_classifier).cuda()\n",
        "#         output1 = self.cnn1(input1)\n",
        "#         output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.\n",
        "#         #output1 = F.max_pool2d(output1,kernel_size=3)\n",
        "#         #output1 = self.pool(2)(output1)\n",
        "#         #output1 = torch.cat((output1,output1),1)\n",
        "#         output2 = self.cnn1(input2)\n",
        "#         output2 = output2.view(output2.size()[0], -1)\n",
        "#         # output2 = self.pool(2)(output2)\n",
        "#         #output2 = torch.cat((output2,output2),1)\n",
        "#         substract_out = torch.subtract(output1,output2)\n",
        "#         diffal2 = torch.multiply(substract_out,substract_out)\n",
        "#         molt = torch.multiply(output1,output2)\n",
        "#         output1al2 = torch.multiply(output1,output1)\n",
        "#         output2al2 = torch.multiply(output2,output2)\n",
        "#         diffdei2 = torch.abs(torch.subtract(output1al2,output2al2))\n",
        "#         output = torch.cat((diffal2, molt,diffdei2),1)\n",
        "#         output = F.relu(self.fc1(output))\n",
        "#         output = F.relu(self.fc2(output))\n",
        "#         output = self.fc3(output)\n",
        "#         return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUvw54nwBb-M"
      },
      "source": [
        "def Trasform(lista):\n",
        "  listatemp = []\n",
        "  for l in lista:\n",
        "      listatemp.append(labelCM[l])\n",
        "  return listatemp\n",
        "\n",
        "def converti(label):\n",
        "      if label == 0:\n",
        "        return \"father-dau\"\n",
        "      elif label == 1:\n",
        "        return \"father-son\"\n",
        "      elif label == 2:\n",
        "        return \"mother-dau\"\n",
        "      elif label == 3:\n",
        "        return \"mother-son\"\n",
        "      else:\n",
        "        return \"Non-Kinship\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyUIBy5_ARBD",
        "outputId": "019d3b6b-bfcb-457c-9879-91f618b1d31a"
      },
      "source": [
        "df0 =  pd.read_csv(pathDir+\"fd.csv\",names=[\"p1\", \"p2\",\"Label\"])\n",
        "df1 =  pd.read_csv(pathDir+\"fs.csv\",names=[\"p1\", \"p2\",\"Label\"])\n",
        "df2 =  pd.read_csv(pathDir+\"md.csv\",names=[\"p1\", \"p2\",\"Label\"])\n",
        "df3 =  pd.read_csv(pathDir+\"ms.csv\",names=[\"p1\", \"p2\",\"Label\"])\n",
        "dfFinal = pd.concat([df0,df1,df2,df3])\n",
        "len(dfFinal)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKYY8bNp__PR"
      },
      "source": [
        "class trainingDataset(Dataset):#Get two images and whether they are related.\n",
        "    \n",
        "    def __init__(self, dataFrame, transform=None):\n",
        "        self.dataFrame = dataFrame #choose either train or val dataset to use\n",
        "        self.transform = transform\n",
        "   \n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img0_info = self.dataFrame.iloc[index][\"p1\"] #for each relationship in train_relationships.csv, the first img comes from first row, and the second is either specially choosed related person or randomly choosed non-related person\n",
        "        img1_info = self.dataFrame.iloc[index][\"p2\"]\n",
        "        label_number = self.dataFrame.iloc[index][\"Label\"] \n",
        "        label_desc = converti(label_number)\n",
        "        if label_desc == 'Non-Kinship':\n",
        "          if img0_info[0:2] == 'fd':\n",
        "             img0_path =pathDir+\"father-dau\"+\"/\"+img0_info\n",
        "             img1_path =pathDir+\"father-dau\"+\"/\"+img1_info\n",
        "          if img0_info[0:2] == 'fs':\n",
        "             img0_path =pathDir+\"father-son\"+\"/\"+img0_info\n",
        "             img1_path =pathDir+\"father-son\"+\"/\"+img1_info\n",
        "          if img0_info[0:2] == 'md':\n",
        "             img0_path =pathDir+\"mother-dau\"+\"/\"+img0_info\n",
        "             img1_path =pathDir+\"mother-dau\"+\"/\"+img1_info\n",
        "             \n",
        "          if img0_info[0:2] == 'ms':\n",
        "             img0_path =pathDir+\"mother-son\"+\"/\"+img0_info\n",
        "             img1_path =pathDir+\"mother-son\"+\"/\"+img1_info\n",
        "        else:\n",
        "          img0_path =pathDir+label_desc+\"/\"+img0_info\n",
        "          img1_path =pathDir+label_desc+\"/\"+img1_info        \n",
        "        img0 = Image.open(img0_path)\n",
        "        img1 = Image.open(img1_path)\n",
        "        \n",
        "        if self.transform is not None:#I think the transform is essential if you want to use GPU, because you have to trans data to tensor first.\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        return img0, img1 , label_number #the returned data from dataloader is img=[batch_size,channels,width,length], should_get_same_class=[batch_size,label]\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.dataFrame)#essential for choose the num of data in one epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3WNF6oeBrFD"
      },
      "source": [
        "pathModel = '/content/drive/My Drive/input/Prova1simple_network-Kinface2_12-06-No-abs.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjEmTCKXDU8b"
      },
      "source": [
        "# pathModel = '/content/drive/MyDrive/input/Prova1simple_network-Kinface2_12-06-4ClassiSIabs3FEParamBlocc.h5'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxZk9s4kBMh7",
        "outputId": "5ee2aa48-19c9-4df5-bd14-a4fb0824270e"
      },
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "net.load_state_dict(torch.load(pathModel))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOYX3OGMBNDr",
        "outputId": "6f7e301b-840b-4bc7-dd37-43400fe1edd4"
      },
      "source": [
        "testset = trainingDataset(dataFrame=dfFinal,\n",
        "                                        transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ]))\n",
        "testloader = DataLoader(testset,\n",
        "                        shuffle=True,\n",
        "                        num_workers=8,\n",
        "                        batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 556
        },
        "id": "0E8fQKlHBQkA",
        "outputId": "4774c536-6597-445e-96d5-98281f209452"
      },
      "source": [
        "predictions=[]\n",
        "lb =[]\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        img0, img1,label = data\n",
        "        img0, img1,label = img0.cuda(), img1.cuda(),label.cuda()\n",
        "        outputs = net(img0,img1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.append(predicted.cpu().numpy())#taking care of here, the output data format is important for transfer\n",
        "        lb.append(label.cpu().numpy())\n",
        "\n",
        "flat_list = [item for sublist in lb for item in sublist]\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "correct = 0\n",
        "for i in range(0,len(flat_list)):\n",
        "    if flat_list[i] == flat_predictions[i]:\n",
        "      correct+=1\n",
        "  \n",
        "labelCM = [\"FD\", \"FS\",\"MD\",\"MS\",\"NK\"]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Trasform(flat_list),Trasform(flat_predictions),labelCM)\n",
        "print(cm)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "fig.colorbar(cax)\n",
        "for i in range(len(cm[0])):\n",
        "  for j in range(len(cm[0])):\n",
        "    ax.text(j, i, format(cm[i][j], \"d\"))\n",
        "ax.set_xticklabels([''] + labelCM)\n",
        "ax.set_yticklabels([''] + labelCM)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.set_cmap('Greens')\n",
        "plt.show()\n",
        "\n",
        "print(cm[0][0]/(cm[0].sum()))\n",
        "print(cm[1][1]/(cm[1].sum()))\n",
        "print(cm[2][2]/(cm[2].sum()))\n",
        "print(cm[3][3]/(cm[3].sum()))\n",
        "print(cm[4][4]/(cm[4].sum()))\n",
        "print(correct/23*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[2 1 0 2 0]\n",
            " [0 4 0 1 0]\n",
            " [1 0 2 5 0]\n",
            " [0 3 0 2 0]\n",
            " [0 0 0 0 0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "0.4\n",
            "0.8\n",
            "0.25\n",
            "0.4\n",
            "nan\n",
            "43.47826086956522\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: RuntimeWarning: invalid value encountered in long_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}