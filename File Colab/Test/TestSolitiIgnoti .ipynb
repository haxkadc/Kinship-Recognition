{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PrimoTestSolitiIgnoti.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0Psx-A6qJxL",
        "outputId": "7bbc7a5a-1ff9-4609-ad39-30aaaa2bb0bc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15o3C2Hm8mz3"
      },
      "source": [
        "#some of blocks below are not used.\n",
        "# Data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import csv\n",
        "# import vgg_pytorch as vp\n",
        "# Data visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Fastai\n",
        "from fastai.vision import *\n",
        "from fastai.vision.models import *\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils\n",
        "import torchvision.datasets as dset\n",
        "\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torchvision.models import *\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.autograd import Variable\n",
        "#import pretrainedmodels\n",
        "\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import dlib\n",
        "import cv2\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "\n",
        "np.random.seed(42)#To make sure that each time you run this kernal, you will get the same beginning parameters.\n",
        "\n",
        "BATCH_SIZE=16\n",
        "NUMBER_EPOCHS=10\n",
        "IMG_SIZE=224\n",
        "#pathModel ='/content/drive/My Drive/input/simple_network-Kinface2-5ClassiSpecchiato.h5'\n",
        "#pathModel ='/content/drive/My Drive/input/simple_network-Kinface2-5Classi25-05.h5'\n",
        "pathModel = '/content/drive/MyDrive/input/Prova1simple_network-Kinface2_12-06-No-abs.h5'\n",
        "pathDir  = 'drive/MyDrive/Soliti__Ignoti/28-04-21//'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8zSl0dzA8tBX"
      },
      "source": [
        "def imshow(img,text=None,should_save=False):#for showing the data you loaded to dataloader\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    \n",
        "\n",
        "def show_plot(iteration,loss):# for showing loss value changed with iter\n",
        "    plt.plot(iteration,loss)\n",
        "    plt.show()\n",
        "\n",
        "def Trasform(lista):\n",
        "  listatemp = []\n",
        "  for l in lista:\n",
        "      listatemp.append(labelCM[l])\n",
        "  return listatemp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgZwuajWWoyb"
      },
      "source": [
        "def estrai(Dirpath):\n",
        "  i = 0\n",
        "  files = [file_i for file_i in os.listdir(Dirpath) if file_i.endswith(\"PNG\")]\n",
        "  for file in files:\n",
        "    imgpath = Dirpath+file\n",
        "    img = cv2.imread(imgpath)\n",
        "    faces = detector(img, 1)\n",
        "    for face_rect in faces:\n",
        "        width = face_rect.right() - face_rect.left()\n",
        "        height = face_rect.bottom() - face_rect.top()\n",
        "        image_to_crop = Image.open(imgpath)\n",
        "        crop_area = (face_rect.left(), face_rect.top(), face_rect.right(), face_rect.bottom())\n",
        "        cropped_image = image_to_crop.crop(crop_area)\n",
        "        crop_size = (width, height)\n",
        "        cropped_image.thumbnail(crop_size)\n",
        "        cropped_image= cropped_image.convert('RGB')\n",
        "        # cropped_image = cropped_image.resize((64,64))\n",
        "        cropped_image.save(Dirpath+\"ImgCropped\" +str(i)+ \".jpg\", \"JPEG\")\n",
        "        i+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HibgSwyb802p"
      },
      "source": [
        "class SiameseNetwork(nn.Module):# A simple implementation of siamese network, ResNet50 is used, and then connected by three fc layer.\n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.cnn1 = vgg16(pretrained=True)# wide_resnet50_2(pretrained=True)##vp.VGG.from_pretrained('vgg16')#resnet50 doesn't work, might because pretrained model recognize all faces as the same.\n",
        "        #self.ccn1.classifier =  nn.Linear(100*100, )\n",
        "        # #Freeze training for all layers\n",
        "        for param in self.cnn1.features.parameters():\n",
        "          param.require_grad = False\n",
        "        for param in self.cnn1.classifier.parameters():\n",
        "          param.require_grad = False\n",
        "\n",
        "\n",
        "\n",
        "        #Newly created modules have require_grad=True by default\n",
        "        num_features = self.cnn1.classifier[3].in_features\n",
        "        features = list(self.cnn1.classifier.children())[:-3] # Remove last layer\n",
        "        \n",
        "        self.cnn1.classifier = nn.Sequential(*features) # Replace the model classifier\n",
        "        # features.extend([nn.Linear(num_features, 1000)]) # Add our layer with 4 outputs\n",
        "        # features.extend([nn.ReLU(inplace=True)])\n",
        "        # features.extend([nn.Dropout()]) # Add our layer with 4 outputs\n",
        "        self.new_classifier = features\n",
        "        # self.pool =  nn.MaxPool2d\n",
        "        self.fc1 = nn.Linear(num_features*2, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 500)\n",
        "        self.fc3 = nn.Linear(500, 5)\n",
        "\n",
        "\n",
        "    def forward(self, input1, input2):#did not know how to let two resnet share the same param.\n",
        "        # self.cnn1.classifier = nn.Sequential(*self.new_classifier).cuda()\n",
        "        output1 = self.cnn1(input1)\n",
        "        output1 = output1.view(output1.size()[0], -1)#make it suitable for fc layer.\n",
        "        #output1 = F.max_pool2d(output1,kernel_size=3)\n",
        "        #output1 = self.pool(2)(output1)\n",
        "        #output1 = torch.cat((output1,output1),1)\n",
        "        output2 = self.cnn1(input2)\n",
        "        output2 = output2.view(output2.size()[0], -1)\n",
        "        # output2 = self.pool(2)(output2)\n",
        "        #output2 = torch.cat((output2,output2),1)\n",
        "        substract_out = torch.subtract(output1,output2)\n",
        "        diffal2 = torch.multiply(substract_out,substract_out)\n",
        "        molt = torch.multiply(output1,output2)\n",
        "        output1al2 = torch.multiply(output1,output1)\n",
        "        output2al2 = torch.multiply(output2,output2)\n",
        "        diffdei2 = torch.subtract(output1al2,output2al2)\n",
        "        output = torch.cat((diffal2, molt),1)\n",
        "        output = F.relu(self.fc1(output))\n",
        "        output = F.relu(self.fc2(output))\n",
        "        output = self.fc3(output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ytpNP1sYCq8"
      },
      "source": [
        "# estrai(pathDir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMc84zT0edyj"
      },
      "source": [
        "imgCropped = [i for i in os.listdir(pathDir) if i.endswith(\"jpg\")]\n",
        "lista = []\n",
        "for i in range(len(imgCropped)-1):\n",
        "  k = i+1\n",
        "  for j in range(k,len(imgCropped)):\n",
        "    lista.append([imgCropped[i],imgCropped[j],\"4\"])\n",
        "\n",
        "\n",
        "with open(pathDir+\"test.csv\", 'w') as myfile:\n",
        "  for p in lista:\n",
        "    wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "    wr.writerow(p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vab0WC8iA4vP"
      },
      "source": [
        "dfTest = pd.read_csv(pathDir+\"test.csv\",names=[\"p1\",\"p2\",\"Label\"])\n",
        "dfTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "hJkqriM4Bblv",
        "outputId": "0a2c6e6c-408f-4766-b4b6-3a8ae648b40a"
      },
      "source": [
        "dfTest[(dfTest[\"p2\"]==\"ImgCropped0.jpg\") &( dfTest[\"p1\"]==\"ImgCropped0.jpg\")]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p1</th>\n",
              "      <th>p2</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ImgCropped0.jpg</td>\n",
              "      <td>ImgCropped1.jpg</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                p1               p2  Label\n",
              "0  ImgCropped0.jpg  ImgCropped1.jpg      4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTf55fkWHgWp",
        "outputId": "ee9606b2-695a-461e-83e3-3385b9ad04de"
      },
      "source": [
        "dfTest[\"p2\"][0] = 'ImgCropped0.jpg'\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyFTiJQ5HnF7"
      },
      "source": [
        "dfTest.to_csv(pathDir+\"test.csv\",index=False)\n",
        "dfTest"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BZEBiYC81pb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhSErL2u80ru",
        "outputId": "c7ec41f9-c781-4329-8260-1a89646ce77b"
      },
      "source": [
        "net = SiameseNetwork().cuda()\n",
        "net.load_state_dict(torch.load(pathModel))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfY4PXz_9BGX"
      },
      "source": [
        "class testDataset(Dataset): #different from train dataset, because the data organized in submission.csv is different from train.csv\n",
        "    \n",
        "    def __init__(self,path,transform=None):\n",
        "        self.path = path\n",
        "        self.test_df =pd.read_csv(self.path+'test.csv')\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self,index):\n",
        "        img0_path = self.test_df.iloc[index].p1\n",
        "        img1_path = self.test_df.iloc[index].p2\n",
        "        label = self.test_df.iloc[index].Label\n",
        "        \n",
        "        img0 = Image.open(self.path+img0_path)\n",
        "        img1 = Image.open(self.path+img1_path)\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        return img0, img1,label\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WO6-HwxN9ig6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b16e79-6753-4522-9346-86bafb844e5c"
      },
      "source": [
        "testset = testDataset(path=pathDir ,transform=transforms.Compose([transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
        "                                                                      transforms.ToTensor()\n",
        "                                                                      ]))\n",
        "testloader = DataLoader(testset,\n",
        "                        shuffle=False,\n",
        "                        num_workers=8,\n",
        "                        batch_size=1)#Both extra workers and batch size lead to data out of order, the submission.csv will be out of order\n",
        "#if you have better method, please tell me! thanks a lot!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfQ7GgkS9l-Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d89ad8de-6527-4401-f9df-f8763dde47d2"
      },
      "source": [
        "predictions=[]\n",
        "lb =[]\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        img0, img1,label = data\n",
        "        img0, img1,label = img0.cuda(), img1.cuda(),label.cuda()\n",
        "        outputs = net(img0,img1)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.append(predicted.cpu().numpy())#taking care of here, the output data format is important for transfer\n",
        "        lb.append(label.cpu().numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGpCCuSTUjxQ"
      },
      "source": [
        "flat_list = [item for sublist in lb for item in sublist]\n",
        "flat_predictions = [item for sublist in predictions for item in sublist]\n",
        "correct = 0\n",
        "for i in range(0,len(flat_list)):\n",
        "    #print(\"Valore Vero:\"+str(flat_list[i]))\n",
        "    #print(\"Valore Predetto:\"+str(flat_predictions[i]))\n",
        "    if flat_list[i] == flat_predictions[i]:\n",
        "      correct+=1\n",
        "  \n",
        "labelCM = [\"FD\", \"FS\",\"MD\",\"MS\",\"NK\"]\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "vvg_iI02U-HD",
        "outputId": "5afaf7a2-b3dd-4c5b-c046-35cf54ec79b9"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(Trasform(flat_list),Trasform(flat_predictions), labelCM)\n",
        "print(cm)\n",
        "\n",
        "fig = plt.figure()\n",
        "\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(cm)\n",
        "fig.colorbar(cax)\n",
        "for i in range(len(cm[0])):\n",
        "  for j in range(len(cm[0])):\n",
        "    ax.text(j, i, format(cm[i][j], \"d\"))\n",
        "ax.set_xticklabels([''] + labelCM)\n",
        "ax.set_yticklabels([''] + labelCM)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.set_cmap('Greens')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  0  0  0  0]\n",
            " [ 0  0  0  0  0]\n",
            " [ 0  0  0  0  0]\n",
            " [ 0  0  0  0  0]\n",
            " [ 8 17  7 12  0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NM_w8_8GVNN8",
        "outputId": "a287f97f-2e2a-4a67-ce90-702d61cd004b"
      },
      "source": [
        "print(cm[0][0]/(cm[0].sum()))\n",
        "print(cm[1][1]/(cm[1].sum()))\n",
        "print(cm[2][2]/(cm[2].sum()))\n",
        "print(cm[3][3]/(cm[3].sum()))\n",
        "print(cm[4][4]/(cm[4].sum()))\n",
        "print(correct/8*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.0\n",
            "nan\n",
            "nan\n",
            "nan\n",
            "0.0\n",
            "12.5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in long_scalars\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}